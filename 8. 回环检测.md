[TOC]

# 基本概念

当相机经过**同一个位置**，采集到了相似的数据，据此得到一些**时隔更加久远**的约束，从而得到一个**全局一致**的估计

回环检测对于 SLAM 的意义：

* 关系到估计的轨迹和地图在**长时间**下的正确性
* 由于回环检测提供了当前数据与所有历史数据的关联 ， 我们还可以利用回环检测进行**重定位**。

## 方法

基于外观的回环检测算法，核心问题是**如何计算图像间的相似性**

设定一种方法计算两张影像之间的相似性评分：$s(\boldsymbol{A},\boldsymbol{B})$ 

图像相减取范数从而衡量图像相似度的方法存在的问题：

* 像素灰度是一种不稳定的测量值 ， 它严重地受环境光照和相机曝光的影响
* 当相机视角发生少量变化时 ， 即使每个物体的光度不变 ， 它们的像素也会在图像中发生位移 ， 造成一个很大的差异值

## 准确率和召回率

$$
\mathrm{Precision}=\frac{TP}{TP+FP}\\
\mathrm{Recall}=\frac{TP}{TP+FN}
$$

* 感知偏差：假阳性
* 感知变异：假阴性

字面意义理解：

* **准确率**：算法提取的所有回环中确实是真实回环的概率
* **召回率**：所有真实回环中被正确检测出来的概率
* 两者通常是一对**矛盾**

作 Precision-Recall 曲线，用**召回率为横轴**，用**准确率为纵轴**时，通常关心的是：

* 整条曲线偏向右上方的程度
* 100%准确率下的召回率
* 50%召回率下的准确度

在 SLAM 中，对准确率的要求更高，对召回率相对宽容一些

# 词袋模型 Bag-of-Words, BoW

目的：用“图像上有哪几种特征”来描述一幅图像

* 确定特征的概念，对应于 BoW 中的“单词” (Word) ，许多单词放在一起就组成了“词典” (Dictionary)
* 确定一幅图像中出现了哪些在字典中定义的概念一一用单词出现的情况（ 或直方图 ）描述整幅图像。这就把一幅图像转换成了一个向量的描述
* 比较上一步中的描述的相似程度

记字典中的单词 $w_1,w_2,w_3$ ，对于任意图像 $A$ ，根据它们含有的单词，可记为 $A=1\cdot w_1+1\cdot w_2+0\cdot w_3$ ，由于字典是固定的，因此只需使用向量 $[1,1,0]^T$ 就可以表达 $A$ 的意义。

* 通过字典和单词，只需**一个向量**就可以描述整幅图像
* 该向量描述的是“图像是否含有某类特征”的信息 ， 比单纯的灰度值更**稳定**。
* 又因为描述向量说的是是否出现，而不管它们在哪儿出现，所以**与物体的空间位置和排列顺序无关**，因此在相机发生少量运动时，只要物体仍在视野中出现，就仍然保证描述向量不发生变化。强调的是 words 的**有无**，而无关其顺序。因此，可以说字典类似于单词的一个集合

# 字典

字典生成问题类似于一个**聚类**问题

假设对大量图像提取了特征点，数量为 $N$ ，利用 K-means 算法获得一个有 $k$ 个单词的字典，每个单词可以看作局部相邻特征点的集合

1. 随机选取 $k$ 个中心点：$c_1,\cdots,c_k$ 
2. 对每一个样本，计算它**与每个中心点之间的距离**，取最小的类作为它的归类
3. 重新计算每个类的中心点
4. 如果每个中心点都变化很小，则算法收敛，退出；否则返回第 2 步

K-means 算法存在的问题：需要指定聚类数量、随机选取中心点使得每次聚类结果都不相同，以及一些效率上的问题。

用 k 叉树来表达字典：类似于层次聚类，是 K-means 的直接扩展。假定有 $N$ 个特征点，希望构建一个深度为 $d$ 、每次分叉为 $k$ 的树，则：

1. 在根节点，用 K-means 把所有样本聚成 $k$ 类（ 实际中为保证聚类均匀性会使用 K-means++ ）。这样就得到了第一层
2. 对第一层的每个节点，把属于该节点的样本再聚成 $k$ 类，得到下一层
3. 依此类推，最后得到叶子层。叶子层即为所谓的 Words

实际上，最终仍在**叶子层**构建了单词，而树结构中的中间节点**仅供快速查找时**使用。这样一个 $k$ 分支、深度为 $k$ 的树，可以容纳 $k^d$ 个单词

另外，在查找某个给定特征对应的单词时，只需将它与每个中间节点的聚类中心比较（一共 $d$ 次），即可找到最后的单词，保证了**对数级别的查找效率**

# 相似度计算

TF-IDF (Term Frequency-Inverse Document Frequency) 频率-逆文档频率

TF 部分的思想：某单词**在一幅图像中经常出现**，它的区分度就高

IDF 部分的思想是：某单词**在字典中出现的频率越低**，分类图像时区分度越高

在建立字典时计算 IDF ：统计某个叶子节点 $w_i$ 中的特征数量相对于所有特征数量的比例，作为 IDF 部分。假设所有特征数量为 $n$ ，$w_i$ 数量为 $n_i$ ，则该单词的 IDF 为：
$$
\mathrm{IDF}_i=\log{\frac{n}{n_i}}
$$
TF 部分是指某个特征在单幅图像中出现的频率，假设图像 $A$ 中单词 $w_i$ 出现了 $n_i$ 次，而一共出现的单词次数为 $n$ ，那么
$$
\mathrm{TF}_i=\frac{n_i}{n}
$$
于是，$w_i$ 的权重等于 TF 乘以 IDF 之积：
$$
\eta_i=\mathrm{TF}_i\times\mathrm{IDF}_i
$$
考虑权重之后，对于某幅图像 $A$ ，它的特征点可以对应到许多个单词，组成它的 BoW：
$$
A=\left\{(w_1,\eta_1),(w_2,\eta_2),\cdots,(w_N,\eta_N)\right\}\triangleq\boldsymbol{v}_A
$$
由于相似的特征可能落到同一个类中，因此实际的 $\boldsymbol{v}_A$ 中会存在大量的零，这是一个稀疏的向量，描述了图像 $A$ 

给定 $\boldsymbol{v}_A$ 和 $\boldsymbol{v}_B$ ，计算其差异：
$$
s(\boldsymbol{v}_A-\boldsymbol{v}_B)=2\sum_{i=1}^N{|\boldsymbol{v}_{Ai}|+|\boldsymbol{v}_{Bi}|-|\boldsymbol{v}_{Ai}-\boldsymbol{v}_{Bi}|}
$$

# 一些讨论

## 相似性评分处理

先验相似度：某时刻关键帧图像与上一时刻的关键帧的相似性
$$
s(\boldsymbol{v}_t,\boldsymbol{v}_{t-\Delta t})
$$
将其他分值参照该值进行归一化
$$
s(\boldsymbol{v}_t,\boldsymbol{v}_{t_j})'=s(\boldsymbol{v}_t,\boldsymbol{v}_{t_j})/s(\boldsymbol{v}_t,\boldsymbol{v}_{t-\Delta t})
$$
这个步骤避免了引人绝对的相似性阈值 ， 使得算法能够适应更多的环境

## 关键帧处理

在检测回环时，必须考虑到关键帧的选取。如果关键帧**选得太近**，那么将导致两个关键帧之间的相似性过高，相比之下不容易检测出历史数据中的回环

从实践上说，用于回环检测的帧最好**稀疏一些**，彼此之间不太相同，又能涵盖整个环境

连续的回环检测，已经用之前的信息消除了累积误差，更多的回环并不会带来更多的信息，因此会把“相近”的回环**聚成一类**，使算法不要反复地检测同一类的回环

## 检测之后的验证

* 词袋的回环检测算法**完全依赖于外观**而**没有利用任何的几何信息**，这导致外观相似的图像容易被当成回环
* 由于词袋**不在乎单词顺序**，**只在意单词有无**的表达方式，更容易引发感知偏差

验证的方法：

* 一种方法是设立回环的**缓存机制**：认为单次检测到的回环并不足以构成良好的约束，而在一段时间中一直检测到的回环，才是正确的回环。这可以看成**时间上的一致性检测**。
* 另一个方法是**空间上的一致性检测**，即对回环检测到的两个帧进行**特征匹配**，估计相机的运动。然后把运动放到之前的位姿图中，检查与之前的估计是否有很大的出入

## 与机器学习的关系

回环检测本身非常像是一个**分类问题**。与传统模式识别的区别在于，回环中的**类别数量很大，而每类的样本很少**。甚至可以把类别当成连续变量而非离散变量，而回环检测相当于两幅图像落入同一类，是很少出现的。

从另一个角度看，回环检测也相当于对“**图像间相似性**”概念的一个学习。

词袋模型本身是一个**非监督的机器学习过程**一一构建词典相当于对特征描述子进行聚类，而树只是对所聚的类的一个快速查找的数据结构。