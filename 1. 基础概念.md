[TOC]

* SLAM 的**目标**：定位、建图

# 各类相机的区别特征

* 单目相机：
  * 从三维向二维的投影，丢失了深度
  * 通过物体在图像上的**运动**形成的视差，恢复场景结构
  * **尺度不确定性**：无法仅凭图像确定尺度因子
* 双目相机：
  * 基线已知
  * 配置标定复杂；深度量程与精度受双目基线与分辨率限制；计算量大
* 深度相机：
  * 红外结构光或 ToF ，节省大量计算资源
  * 测量范围窄；噪声大；视野小；易受日光干扰；无法测量透射材质

# 经典视觉SLAM框架

| 传感器信息读取 | 前端视觉里程计 | 后端（非线性）优化 | 回环检测 | 建图 |
| :------------: | :------------: | :----------------: | :------: | :--: |

* 视觉里程计 VO：
  * 通过相邻帧间的图像估计相机运动，并恢复场景的空间结构
  * 由于其仅使用相邻帧进行估计，因此会出现**累积漂移**
* 后端优化：
  * **本质**：对运动主体自身和周围环境空间不确定性的估计
  * 前端（VO）与计算机视觉研究领域更为相关（图像特征提取与匹配），后端则主要是滤波与非线性算法
* 回环检测：
  * 解决位置估计随时间漂移的问题
  * 实质上是一种计算图像数据相似性的算法
* 建图：
  * 度量地图
    * 稀疏地图、稠密地图（Grid, Voxel）
    * 冗余细节；大规模下出现的一致性问题
  * 拓扑地图：Graph

# SLAM 问题的数学建模

* 运动方程：

$$
\boldsymbol{x}_k=f(\boldsymbol{x}_{k-1},\boldsymbol{u}_k,\boldsymbol{w}_k)
$$

其中， $\boldsymbol{u}_k$ 是运动传感器的读数或输入，$\boldsymbol{w}_k$ 是该过程中加入的噪声

* 观测方程：

$$
\boldsymbol{z}_{k,j}=h(\boldsymbol{y}_j,\boldsymbol{x}_k,\boldsymbol{v}_{k,j})
$$

其中， $\boldsymbol{v}_{k,j}$ 是这次观测中的噪声